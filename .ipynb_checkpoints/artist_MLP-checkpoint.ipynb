{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "artist_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDi_gCTYZYgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a275d1-48af-4082-e6f0-1355072c8cc3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tI-HAWPaD78"
      },
      "source": [
        "import tensorflow.keras as ker\n",
        "from tensorflow.keras.layers import Input,Dense,Flatten,Dropout,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose,concatenate,add,MaxPool2D\n",
        "from tensorflow.keras.layers import BatchNormalization,Conv3D,ConvLSTM2D,Conv3DTranspose,Permute,MaxPooling3D,UpSampling3D,GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose,Concatenate,ReLU\n",
        "from tensorflow.keras.activations import sigmoid\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers, utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.applications import ResNet50, ResNet101, ResNet152V2\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from scipy import stats\n",
        "from PIL import Image\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import sys  \n",
        "sys.path.insert(0, '/content/drive/My Drive/Colab Notebooks/GraphNetwork/Wikiart3/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBWhD2VOvn5t"
      },
      "source": [
        "seed = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "105ObubpvFTu"
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/GraphNetwork/Wikiart3/'\n",
        "model_path = path + '/models/artist/model_artist_MLP_' + str(seed) + '.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE67vr4jUDdv"
      },
      "source": [
        "lines = []\n",
        "with open(path + 'Style/style_class.txt') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "style_names = []\n",
        "for line in lines:\n",
        "  item = line.split()\n",
        "  style_names.append(item[1])\n",
        "\n",
        "class_to_style = dict(zip(range(27), style_names))\n",
        "style_to_class = dict(zip(style_names, range(27)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVgiL59rRmTr"
      },
      "source": [
        "lines = []\n",
        "with open(path + 'Genre/genre_class') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "genre_names = []\n",
        "for line in lines:\n",
        "  item = line.split()\n",
        "  genre_names.append(item[1])\n",
        "\n",
        "class_to_genre = dict(zip(range(10), genre_names))\n",
        "genre_to_class = dict(zip(genre_names, range(10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBRAE8ftRqAC"
      },
      "source": [
        "lines = []\n",
        "with open(path + 'Artist/artist_class') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "artist_names = []\n",
        "for line in lines:\n",
        "  item = line.split()\n",
        "  artist_names.append(item[1])\n",
        "\n",
        "class_to_artist = dict(zip(range(23), artist_names))\n",
        "artist_to_class = dict(zip(artist_names, range(23)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG_w48-CRrC3"
      },
      "source": [
        "genre_list = np.genfromtxt(path + 'Genre/genre_train.csv', delimiter=',', dtype= str)\n",
        "genre_list = np.concatenate((genre_list, np.genfromtxt(path + 'Genre/genre_val.csv', delimiter=',', dtype= str)), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaVGBxHGRq9V"
      },
      "source": [
        "artist_list = np.genfromtxt(path + 'Artist/artist_train', delimiter=',,', dtype= str)\n",
        "artist_list = np.concatenate((artist_list, np.genfromtxt(path + 'Artist/artist_val', delimiter=',,', dtype= str)), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPGPIvAfZAK4"
      },
      "source": [
        "data_names = np.load(path + 'data/artist/artist_names.npy')\n",
        "x = np.load(path + 'data/artist/artist_data.npy')\n",
        "y_artist = np.load(path + 'data/artist/artist_labels.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvk-XEvC2J69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4e86a3-1b8c-4766-a227-31cdcadde920"
      },
      "source": [
        "data_names.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17804"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_55E3nGBw1Ny"
      },
      "source": [
        "y_artist[y_artist==22] = 19"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKLV7l20wUwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c19173f-e453-43f0-ef9f-f31fe983afbe"
      },
      "source": [
        "unique, counts = np.unique(y_artist, return_counts=True)\n",
        "print(unique)\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21.]\n",
            "[ 828  438  887  550 1334  611  555  753  539  577  520  784  765  572\n",
            " 1304  747  579 1400  915 1890  777  479]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwAVwzUAS0-M"
      },
      "source": [
        "class_size = 22\n",
        "input_shape = (2048,)\n",
        "input_feature = Input(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPrmBanWS07l"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y_artist, test_size=0.15, random_state=seed)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.17, random_state=seed)\n",
        "\n",
        "train_size = x_train.shape[0]\n",
        "val_size = x_val.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl_m9H8_-6Ok"
      },
      "source": [
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                 classes=np.unique(y_train),\n",
        "                                                 y=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uJ4gvDhAqv1"
      },
      "source": [
        "class_weights = {i : class_weights[i] for i in range(class_size)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLdHl9tvDLYW"
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drOTsulbS04i"
      },
      "source": [
        "def fcnn(encoded):\n",
        "    dense0 = Dropout(0.2)(encoded)\n",
        "    dense0 = BatchNormalization()(dense0)\n",
        "\n",
        "    dense1 = Dense(256)(dense0)\n",
        "    dense1 = Dropout(0.3)(dense1)\n",
        "    dense1 = BatchNormalization()(dense1)\n",
        "    dense1 = ReLU()(dense1)\n",
        "    \n",
        "    dense2 = Dense(32)(dense1)\n",
        "    dense2 = Dropout(0.4)(dense2)\n",
        "    dense2 = BatchNormalization()(dense2)\n",
        "    dense2 = ReLU()(dense2)\n",
        "\n",
        "    out = Dense(class_size, activation='softmax')(dense2)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbo780kCS00S"
      },
      "source": [
        "adam = Adam(learning_rate=0.001)\n",
        "model_full = Model(input_feature, fcnn(input_feature))\n",
        "model_full.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6_noN_0S0sy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8c9af1b-6e7f-4156-9423-68fd5b316112"
      },
      "source": [
        "try:\n",
        "    model_full.load_weights(model_path)\n",
        "except:\n",
        "    early_stopping = [EarlyStopping(monitor='val_loss', patience=50),\n",
        "                      ModelCheckpoint(filepath=model_path, monitor='val_loss', save_best_only=True)]\n",
        "    history = model_full.fit(x_train,\n",
        "                             y_train,\n",
        "                             epochs=10000,\n",
        "                             batch_size=train_size,\n",
        "                             class_weight=class_weights,\n",
        "                             validation_data=(x_val, y_val),\n",
        "                             callbacks=[early_stopping],\n",
        "                             shuffle=True\n",
        "                             )\n",
        "    model_full.load_weights(model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.3593 - accuracy: 0.0424 - val_loss: 22.2528 - val_accuracy: 0.0466\n",
            "Epoch 2/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 3.2228 - accuracy: 0.0531 - val_loss: 22.3976 - val_accuracy: 0.0474\n",
            "Epoch 3/10000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 3.1651 - accuracy: 0.0580 - val_loss: 22.2294 - val_accuracy: 0.0393\n",
            "Epoch 4/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 3.1013 - accuracy: 0.0676 - val_loss: 20.2958 - val_accuracy: 0.0389\n",
            "Epoch 5/10000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 3.0692 - accuracy: 0.0719 - val_loss: 17.7290 - val_accuracy: 0.0595\n",
            "Epoch 6/10000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 3.0445 - accuracy: 0.0813 - val_loss: 16.1415 - val_accuracy: 0.0583\n",
            "Epoch 7/10000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 3.0050 - accuracy: 0.0896 - val_loss: 14.8432 - val_accuracy: 0.0560\n",
            "Epoch 8/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 2.9859 - accuracy: 0.0950 - val_loss: 13.9473 - val_accuracy: 0.0529\n",
            "Epoch 9/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.9695 - accuracy: 0.1042 - val_loss: 13.1480 - val_accuracy: 0.0556\n",
            "Epoch 10/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.9429 - accuracy: 0.1109 - val_loss: 12.3775 - val_accuracy: 0.0548\n",
            "Epoch 11/10000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 2.9221 - accuracy: 0.1142 - val_loss: 11.8304 - val_accuracy: 0.0614\n",
            "Epoch 12/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.9168 - accuracy: 0.1209 - val_loss: 11.3189 - val_accuracy: 0.0645\n",
            "Epoch 13/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.9027 - accuracy: 0.1225 - val_loss: 10.8041 - val_accuracy: 0.0723\n",
            "Epoch 14/10000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 2.8883 - accuracy: 0.1328 - val_loss: 10.3080 - val_accuracy: 0.0696\n",
            "Epoch 15/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 2.8730 - accuracy: 0.1393 - val_loss: 9.7424 - val_accuracy: 0.0727\n",
            "Epoch 16/10000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 2.8634 - accuracy: 0.1442 - val_loss: 9.1886 - val_accuracy: 0.0805\n",
            "Epoch 17/10000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 2.8489 - accuracy: 0.1498 - val_loss: 8.6418 - val_accuracy: 0.0824\n",
            "Epoch 18/10000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 2.8347 - accuracy: 0.1564 - val_loss: 8.0974 - val_accuracy: 0.0847\n",
            "Epoch 19/10000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 2.8262 - accuracy: 0.1551 - val_loss: 7.5996 - val_accuracy: 0.0874\n",
            "Epoch 20/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.8167 - accuracy: 0.1643 - val_loss: 7.1828 - val_accuracy: 0.0898\n",
            "Epoch 21/10000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 2.8003 - accuracy: 0.1681 - val_loss: 6.7725 - val_accuracy: 0.0964\n",
            "Epoch 22/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.7879 - accuracy: 0.1780 - val_loss: 6.4472 - val_accuracy: 0.1007\n",
            "Epoch 23/10000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 2.7868 - accuracy: 0.1760 - val_loss: 6.2062 - val_accuracy: 0.1073\n",
            "Epoch 24/10000\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 2.7792 - accuracy: 0.1807 - val_loss: 6.0234 - val_accuracy: 0.1115\n",
            "Epoch 25/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 2.7745 - accuracy: 0.1827 - val_loss: 5.8630 - val_accuracy: 0.1131\n",
            "Epoch 26/10000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 2.7606 - accuracy: 0.1848 - val_loss: 5.7331 - val_accuracy: 0.1131\n",
            "Epoch 27/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.7439 - accuracy: 0.1946 - val_loss: 5.6070 - val_accuracy: 0.1150\n",
            "Epoch 28/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 2.7480 - accuracy: 0.1908 - val_loss: 5.4799 - val_accuracy: 0.1162\n",
            "Epoch 29/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.7398 - accuracy: 0.1906 - val_loss: 5.3705 - val_accuracy: 0.1193\n",
            "Epoch 30/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.7311 - accuracy: 0.1997 - val_loss: 5.2965 - val_accuracy: 0.1213\n",
            "Epoch 31/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.7173 - accuracy: 0.2005 - val_loss: 5.2238 - val_accuracy: 0.1244\n",
            "Epoch 32/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 2.7139 - accuracy: 0.2007 - val_loss: 5.1478 - val_accuracy: 0.1255\n",
            "Epoch 33/10000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 2.7023 - accuracy: 0.2007 - val_loss: 5.0446 - val_accuracy: 0.1275\n",
            "Epoch 34/10000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 2.6941 - accuracy: 0.2041 - val_loss: 4.9244 - val_accuracy: 0.1321\n",
            "Epoch 35/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 2.6892 - accuracy: 0.2145 - val_loss: 4.7810 - val_accuracy: 0.1349\n",
            "Epoch 36/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.6809 - accuracy: 0.2175 - val_loss: 4.6095 - val_accuracy: 0.1372\n",
            "Epoch 37/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.6762 - accuracy: 0.2173 - val_loss: 4.4377 - val_accuracy: 0.1395\n",
            "Epoch 38/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.6718 - accuracy: 0.2132 - val_loss: 4.2681 - val_accuracy: 0.1434\n",
            "Epoch 39/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.6660 - accuracy: 0.2198 - val_loss: 4.1242 - val_accuracy: 0.1442\n",
            "Epoch 40/10000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 2.6547 - accuracy: 0.2209 - val_loss: 3.9958 - val_accuracy: 0.1481\n",
            "Epoch 41/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 2.6411 - accuracy: 0.2241 - val_loss: 3.9014 - val_accuracy: 0.1500\n",
            "Epoch 42/10000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 2.6377 - accuracy: 0.2294 - val_loss: 3.8439 - val_accuracy: 0.1489\n",
            "Epoch 43/10000\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 2.6371 - accuracy: 0.2262 - val_loss: 3.7949 - val_accuracy: 0.1508\n",
            "Epoch 44/10000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 2.6285 - accuracy: 0.2302 - val_loss: 3.7364 - val_accuracy: 0.1500\n",
            "Epoch 45/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 2.6279 - accuracy: 0.2319 - val_loss: 3.6877 - val_accuracy: 0.1516\n",
            "Epoch 46/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.6113 - accuracy: 0.2369 - val_loss: 3.6320 - val_accuracy: 0.1539\n",
            "Epoch 47/10000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 2.6094 - accuracy: 0.2367 - val_loss: 3.5552 - val_accuracy: 0.1574\n",
            "Epoch 48/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.6027 - accuracy: 0.2389 - val_loss: 3.4833 - val_accuracy: 0.1609\n",
            "Epoch 49/10000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 2.5962 - accuracy: 0.2447 - val_loss: 3.4102 - val_accuracy: 0.1667\n",
            "Epoch 50/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.5859 - accuracy: 0.2477 - val_loss: 3.3541 - val_accuracy: 0.1691\n",
            "Epoch 51/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.5845 - accuracy: 0.2508 - val_loss: 3.3242 - val_accuracy: 0.1691\n",
            "Epoch 52/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.5724 - accuracy: 0.2502 - val_loss: 3.2938 - val_accuracy: 0.1687\n",
            "Epoch 53/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.5799 - accuracy: 0.2455 - val_loss: 3.2535 - val_accuracy: 0.1675\n",
            "Epoch 54/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.5602 - accuracy: 0.2580 - val_loss: 3.2138 - val_accuracy: 0.1698\n",
            "Epoch 55/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.5515 - accuracy: 0.2551 - val_loss: 3.1622 - val_accuracy: 0.1714\n",
            "Epoch 56/10000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 2.5405 - accuracy: 0.2618 - val_loss: 3.1089 - val_accuracy: 0.1737\n",
            "Epoch 57/10000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 2.5407 - accuracy: 0.2564 - val_loss: 3.0648 - val_accuracy: 0.1799\n",
            "Epoch 58/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 2.5367 - accuracy: 0.2676 - val_loss: 3.0305 - val_accuracy: 0.1854\n",
            "Epoch 59/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.5248 - accuracy: 0.2643 - val_loss: 2.9971 - val_accuracy: 0.1873\n",
            "Epoch 60/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.5226 - accuracy: 0.2643 - val_loss: 2.9681 - val_accuracy: 0.1897\n",
            "Epoch 61/10000\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 2.5187 - accuracy: 0.2594 - val_loss: 2.9455 - val_accuracy: 0.1924\n",
            "Epoch 62/10000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 2.5149 - accuracy: 0.2629 - val_loss: 2.9180 - val_accuracy: 0.1939\n",
            "Epoch 63/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.5074 - accuracy: 0.2706 - val_loss: 2.8842 - val_accuracy: 0.1951\n",
            "Epoch 64/10000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 2.4915 - accuracy: 0.2717 - val_loss: 2.8465 - val_accuracy: 0.1978\n",
            "Epoch 65/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.4917 - accuracy: 0.2718 - val_loss: 2.8057 - val_accuracy: 0.1990\n",
            "Epoch 66/10000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 2.4909 - accuracy: 0.2734 - val_loss: 2.7743 - val_accuracy: 0.2029\n",
            "Epoch 67/10000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 2.4844 - accuracy: 0.2756 - val_loss: 2.7484 - val_accuracy: 0.2044\n",
            "Epoch 68/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.4847 - accuracy: 0.2779 - val_loss: 2.7295 - val_accuracy: 0.2087\n",
            "Epoch 69/10000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 2.4720 - accuracy: 0.2764 - val_loss: 2.7091 - val_accuracy: 0.2145\n",
            "Epoch 70/10000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 2.4640 - accuracy: 0.2824 - val_loss: 2.6880 - val_accuracy: 0.2157\n",
            "Epoch 71/10000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 2.4656 - accuracy: 0.2779 - val_loss: 2.6660 - val_accuracy: 0.2180\n",
            "Epoch 72/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.4541 - accuracy: 0.2859 - val_loss: 2.6404 - val_accuracy: 0.2219\n",
            "Epoch 73/10000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 2.4574 - accuracy: 0.2835 - val_loss: 2.6224 - val_accuracy: 0.2215\n",
            "Epoch 74/10000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 2.4356 - accuracy: 0.2944 - val_loss: 2.6080 - val_accuracy: 0.2243\n",
            "Epoch 75/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.4308 - accuracy: 0.2900 - val_loss: 2.5944 - val_accuracy: 0.2320\n",
            "Epoch 76/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 2.4408 - accuracy: 0.2868 - val_loss: 2.5818 - val_accuracy: 0.2324\n",
            "Epoch 77/10000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 2.4161 - accuracy: 0.2939 - val_loss: 2.5715 - val_accuracy: 0.2371\n",
            "Epoch 78/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.4281 - accuracy: 0.2923 - val_loss: 2.5602 - val_accuracy: 0.2394\n",
            "Epoch 79/10000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 2.4216 - accuracy: 0.2955 - val_loss: 2.5478 - val_accuracy: 0.2425\n",
            "Epoch 80/10000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 2.4154 - accuracy: 0.2988 - val_loss: 2.5304 - val_accuracy: 0.2464\n",
            "Epoch 81/10000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 2.4056 - accuracy: 0.2970 - val_loss: 2.5109 - val_accuracy: 0.2530\n",
            "Epoch 82/10000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 2.4071 - accuracy: 0.2969 - val_loss: 2.4918 - val_accuracy: 0.2612\n",
            "Epoch 83/10000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 2.3929 - accuracy: 0.3026 - val_loss: 2.4812 - val_accuracy: 0.2623\n",
            "Epoch 84/10000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 2.3912 - accuracy: 0.3021 - val_loss: 2.4787 - val_accuracy: 0.2662\n",
            "Epoch 85/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.3894 - accuracy: 0.2986 - val_loss: 2.4836 - val_accuracy: 0.2662\n",
            "Epoch 86/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3773 - accuracy: 0.3057 - val_loss: 2.4917 - val_accuracy: 0.2651\n",
            "Epoch 87/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3813 - accuracy: 0.3048 - val_loss: 2.4947 - val_accuracy: 0.2631\n",
            "Epoch 88/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3713 - accuracy: 0.3084 - val_loss: 2.4878 - val_accuracy: 0.2678\n",
            "Epoch 89/10000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 2.3667 - accuracy: 0.3111 - val_loss: 2.4721 - val_accuracy: 0.2740\n",
            "Epoch 90/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 2.3729 - accuracy: 0.3096 - val_loss: 2.4536 - val_accuracy: 0.2787\n",
            "Epoch 91/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.3551 - accuracy: 0.3058 - val_loss: 2.4408 - val_accuracy: 0.2845\n",
            "Epoch 92/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.3549 - accuracy: 0.3125 - val_loss: 2.4345 - val_accuracy: 0.2857\n",
            "Epoch 93/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3550 - accuracy: 0.3127 - val_loss: 2.4357 - val_accuracy: 0.2845\n",
            "Epoch 94/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.3437 - accuracy: 0.3145 - val_loss: 2.4388 - val_accuracy: 0.2837\n",
            "Epoch 95/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3442 - accuracy: 0.3170 - val_loss: 2.4387 - val_accuracy: 0.2818\n",
            "Epoch 96/10000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 2.3359 - accuracy: 0.3184 - val_loss: 2.4341 - val_accuracy: 0.2829\n",
            "Epoch 97/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.3358 - accuracy: 0.3203 - val_loss: 2.4240 - val_accuracy: 0.2911\n",
            "Epoch 98/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 2.3293 - accuracy: 0.3127 - val_loss: 2.4100 - val_accuracy: 0.2997\n",
            "Epoch 99/10000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 2.3197 - accuracy: 0.3205 - val_loss: 2.3968 - val_accuracy: 0.3047\n",
            "Epoch 100/10000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 2.3233 - accuracy: 0.3162 - val_loss: 2.3873 - val_accuracy: 0.3094\n",
            "Epoch 101/10000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 2.3240 - accuracy: 0.3189 - val_loss: 2.3783 - val_accuracy: 0.3125\n",
            "Epoch 102/10000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 2.3144 - accuracy: 0.3229 - val_loss: 2.3750 - val_accuracy: 0.3109\n",
            "Epoch 103/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3105 - accuracy: 0.3249 - val_loss: 2.3757 - val_accuracy: 0.3113\n",
            "Epoch 104/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.3033 - accuracy: 0.3268 - val_loss: 2.3767 - val_accuracy: 0.3133\n",
            "Epoch 105/10000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2965 - accuracy: 0.3278 - val_loss: 2.3778 - val_accuracy: 0.3171\n",
            "Epoch 106/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2898 - accuracy: 0.3303 - val_loss: 2.3771 - val_accuracy: 0.3171\n",
            "Epoch 107/10000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 2.2915 - accuracy: 0.3271 - val_loss: 2.3748 - val_accuracy: 0.3179\n",
            "Epoch 108/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.2804 - accuracy: 0.3317 - val_loss: 2.3685 - val_accuracy: 0.3195\n",
            "Epoch 109/10000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 2.2796 - accuracy: 0.3308 - val_loss: 2.3622 - val_accuracy: 0.3230\n",
            "Epoch 110/10000\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 2.2788 - accuracy: 0.3248 - val_loss: 2.3565 - val_accuracy: 0.3210\n",
            "Epoch 111/10000\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 2.2672 - accuracy: 0.3393 - val_loss: 2.3495 - val_accuracy: 0.3237\n",
            "Epoch 112/10000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 2.2607 - accuracy: 0.3381 - val_loss: 2.3417 - val_accuracy: 0.3280\n",
            "Epoch 113/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 2.2638 - accuracy: 0.3326 - val_loss: 2.3326 - val_accuracy: 0.3335\n",
            "Epoch 114/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.2717 - accuracy: 0.3373 - val_loss: 2.3268 - val_accuracy: 0.3370\n",
            "Epoch 115/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.2643 - accuracy: 0.3334 - val_loss: 2.3214 - val_accuracy: 0.3420\n",
            "Epoch 116/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.2556 - accuracy: 0.3398 - val_loss: 2.3180 - val_accuracy: 0.3373\n",
            "Epoch 117/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.2529 - accuracy: 0.3388 - val_loss: 2.3141 - val_accuracy: 0.3370\n",
            "Epoch 118/10000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 2.2446 - accuracy: 0.3437 - val_loss: 2.3106 - val_accuracy: 0.3397\n",
            "Epoch 119/10000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 2.2324 - accuracy: 0.3420 - val_loss: 2.3058 - val_accuracy: 0.3381\n",
            "Epoch 120/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.2425 - accuracy: 0.3370 - val_loss: 2.3004 - val_accuracy: 0.3405\n",
            "Epoch 121/10000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 2.2440 - accuracy: 0.3365 - val_loss: 2.2963 - val_accuracy: 0.3447\n",
            "Epoch 122/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 2.2267 - accuracy: 0.3451 - val_loss: 2.2936 - val_accuracy: 0.3478\n",
            "Epoch 123/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 2.2373 - accuracy: 0.3453 - val_loss: 2.2901 - val_accuracy: 0.3498\n",
            "Epoch 124/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.2205 - accuracy: 0.3447 - val_loss: 2.2856 - val_accuracy: 0.3510\n",
            "Epoch 125/10000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 2.2259 - accuracy: 0.3408 - val_loss: 2.2840 - val_accuracy: 0.3510\n",
            "Epoch 126/10000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 2.2235 - accuracy: 0.3404 - val_loss: 2.2834 - val_accuracy: 0.3510\n",
            "Epoch 127/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.2202 - accuracy: 0.3488 - val_loss: 2.2797 - val_accuracy: 0.3513\n",
            "Epoch 128/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 2.2074 - accuracy: 0.3513 - val_loss: 2.2770 - val_accuracy: 0.3537\n",
            "Epoch 129/10000\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 2.2050 - accuracy: 0.3455 - val_loss: 2.2729 - val_accuracy: 0.3537\n",
            "Epoch 130/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.2030 - accuracy: 0.3543 - val_loss: 2.2682 - val_accuracy: 0.3572\n",
            "Epoch 131/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.1961 - accuracy: 0.3466 - val_loss: 2.2634 - val_accuracy: 0.3579\n",
            "Epoch 132/10000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 2.2029 - accuracy: 0.3503 - val_loss: 2.2602 - val_accuracy: 0.3576\n",
            "Epoch 133/10000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 2.1876 - accuracy: 0.3519 - val_loss: 2.2597 - val_accuracy: 0.3568\n",
            "Epoch 134/10000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 2.1844 - accuracy: 0.3486 - val_loss: 2.2592 - val_accuracy: 0.3548\n",
            "Epoch 135/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.1836 - accuracy: 0.3510 - val_loss: 2.2569 - val_accuracy: 0.3541\n",
            "Epoch 136/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.1900 - accuracy: 0.3551 - val_loss: 2.2532 - val_accuracy: 0.3579\n",
            "Epoch 137/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 2.1840 - accuracy: 0.3563 - val_loss: 2.2517 - val_accuracy: 0.3614\n",
            "Epoch 138/10000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 2.1793 - accuracy: 0.3502 - val_loss: 2.2476 - val_accuracy: 0.3626\n",
            "Epoch 139/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 2.1771 - accuracy: 0.3550 - val_loss: 2.2439 - val_accuracy: 0.3657\n",
            "Epoch 140/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.1758 - accuracy: 0.3517 - val_loss: 2.2397 - val_accuracy: 0.3653\n",
            "Epoch 141/10000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 2.1665 - accuracy: 0.3572 - val_loss: 2.2347 - val_accuracy: 0.3638\n",
            "Epoch 142/10000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 2.1690 - accuracy: 0.3584 - val_loss: 2.2290 - val_accuracy: 0.3649\n",
            "Epoch 143/10000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 2.1700 - accuracy: 0.3590 - val_loss: 2.2221 - val_accuracy: 0.3673\n",
            "Epoch 144/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.1554 - accuracy: 0.3605 - val_loss: 2.2169 - val_accuracy: 0.3696\n",
            "Epoch 145/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 2.1707 - accuracy: 0.3566 - val_loss: 2.2119 - val_accuracy: 0.3727\n",
            "Epoch 146/10000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 2.1537 - accuracy: 0.3623 - val_loss: 2.2116 - val_accuracy: 0.3743\n",
            "Epoch 147/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.1480 - accuracy: 0.3641 - val_loss: 2.2127 - val_accuracy: 0.3747\n",
            "Epoch 148/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.1379 - accuracy: 0.3689 - val_loss: 2.2125 - val_accuracy: 0.3766\n",
            "Epoch 149/10000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 2.1459 - accuracy: 0.3604 - val_loss: 2.2096 - val_accuracy: 0.3762\n",
            "Epoch 150/10000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 2.1427 - accuracy: 0.3627 - val_loss: 2.2047 - val_accuracy: 0.3770\n",
            "Epoch 151/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.1389 - accuracy: 0.3612 - val_loss: 2.2001 - val_accuracy: 0.3789\n",
            "Epoch 152/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.1346 - accuracy: 0.3664 - val_loss: 2.1955 - val_accuracy: 0.3797\n",
            "Epoch 153/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 2.1375 - accuracy: 0.3583 - val_loss: 2.1927 - val_accuracy: 0.3809\n",
            "Epoch 154/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.1263 - accuracy: 0.3689 - val_loss: 2.1907 - val_accuracy: 0.3801\n",
            "Epoch 155/10000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 2.1229 - accuracy: 0.3679 - val_loss: 2.1867 - val_accuracy: 0.3809\n",
            "Epoch 156/10000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 2.1206 - accuracy: 0.3627 - val_loss: 2.1838 - val_accuracy: 0.3824\n",
            "Epoch 157/10000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 2.1241 - accuracy: 0.3637 - val_loss: 2.1832 - val_accuracy: 0.3852\n",
            "Epoch 158/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.1180 - accuracy: 0.3713 - val_loss: 2.1803 - val_accuracy: 0.3871\n",
            "Epoch 159/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 2.1143 - accuracy: 0.3670 - val_loss: 2.1778 - val_accuracy: 0.3855\n",
            "Epoch 160/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 2.1105 - accuracy: 0.3685 - val_loss: 2.1763 - val_accuracy: 0.3887\n",
            "Epoch 161/10000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 2.1149 - accuracy: 0.3717 - val_loss: 2.1756 - val_accuracy: 0.3941\n",
            "Epoch 162/10000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 2.1039 - accuracy: 0.3721 - val_loss: 2.1741 - val_accuracy: 0.3898\n",
            "Epoch 163/10000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 2.1162 - accuracy: 0.3697 - val_loss: 2.1716 - val_accuracy: 0.3894\n",
            "Epoch 164/10000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 2.1017 - accuracy: 0.3643 - val_loss: 2.1687 - val_accuracy: 0.3921\n",
            "Epoch 165/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.0946 - accuracy: 0.3764 - val_loss: 2.1680 - val_accuracy: 0.3918\n",
            "Epoch 166/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 2.0918 - accuracy: 0.3749 - val_loss: 2.1668 - val_accuracy: 0.3883\n",
            "Epoch 167/10000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 2.0850 - accuracy: 0.3714 - val_loss: 2.1652 - val_accuracy: 0.3902\n",
            "Epoch 168/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 2.0793 - accuracy: 0.3783 - val_loss: 2.1630 - val_accuracy: 0.3883\n",
            "Epoch 169/10000\n",
            "1/1 [==============================] - 1s 609ms/step - loss: 2.0739 - accuracy: 0.3800 - val_loss: 2.1570 - val_accuracy: 0.3921\n",
            "Epoch 170/10000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 2.0795 - accuracy: 0.3773 - val_loss: 2.1514 - val_accuracy: 0.3945\n",
            "Epoch 171/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 2.0798 - accuracy: 0.3771 - val_loss: 2.1474 - val_accuracy: 0.3925\n",
            "Epoch 172/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.0713 - accuracy: 0.3803 - val_loss: 2.1469 - val_accuracy: 0.3933\n",
            "Epoch 173/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.0693 - accuracy: 0.3772 - val_loss: 2.1475 - val_accuracy: 0.3953\n",
            "Epoch 174/10000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 2.0742 - accuracy: 0.3762 - val_loss: 2.1455 - val_accuracy: 0.3991\n",
            "Epoch 175/10000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 2.0631 - accuracy: 0.3791 - val_loss: 2.1422 - val_accuracy: 0.4023\n",
            "Epoch 176/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.0780 - accuracy: 0.3794 - val_loss: 2.1390 - val_accuracy: 0.3976\n",
            "Epoch 177/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.0533 - accuracy: 0.3831 - val_loss: 2.1384 - val_accuracy: 0.3949\n",
            "Epoch 178/10000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 2.0601 - accuracy: 0.3827 - val_loss: 2.1364 - val_accuracy: 0.3898\n",
            "Epoch 179/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 2.0654 - accuracy: 0.3770 - val_loss: 2.1341 - val_accuracy: 0.3933\n",
            "Epoch 180/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.0439 - accuracy: 0.3871 - val_loss: 2.1349 - val_accuracy: 0.3953\n",
            "Epoch 181/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.0530 - accuracy: 0.3910 - val_loss: 2.1347 - val_accuracy: 0.3976\n",
            "Epoch 182/10000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 2.0423 - accuracy: 0.3903 - val_loss: 2.1323 - val_accuracy: 0.3984\n",
            "Epoch 183/10000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 2.0355 - accuracy: 0.3870 - val_loss: 2.1307 - val_accuracy: 0.3964\n",
            "Epoch 184/10000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 2.0362 - accuracy: 0.3857 - val_loss: 2.1298 - val_accuracy: 0.3964\n",
            "Epoch 185/10000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 2.0497 - accuracy: 0.3870 - val_loss: 2.1266 - val_accuracy: 0.3972\n",
            "Epoch 186/10000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 2.0344 - accuracy: 0.3916 - val_loss: 2.1245 - val_accuracy: 0.3953\n",
            "Epoch 187/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.0404 - accuracy: 0.3842 - val_loss: 2.1228 - val_accuracy: 0.3968\n",
            "Epoch 188/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.0413 - accuracy: 0.3854 - val_loss: 2.1243 - val_accuracy: 0.4003\n",
            "Epoch 189/10000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 2.0254 - accuracy: 0.3894 - val_loss: 2.1222 - val_accuracy: 0.3968\n",
            "Epoch 190/10000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 2.0287 - accuracy: 0.3863 - val_loss: 2.1181 - val_accuracy: 0.3991\n",
            "Epoch 191/10000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 2.0351 - accuracy: 0.3838 - val_loss: 2.1174 - val_accuracy: 0.4023\n",
            "Epoch 192/10000\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 2.0152 - accuracy: 0.3908 - val_loss: 2.1149 - val_accuracy: 0.4003\n",
            "Epoch 193/10000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 2.0190 - accuracy: 0.3886 - val_loss: 2.1116 - val_accuracy: 0.3988\n",
            "Epoch 194/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 2.0208 - accuracy: 0.3904 - val_loss: 2.1094 - val_accuracy: 0.3972\n",
            "Epoch 195/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.0198 - accuracy: 0.3895 - val_loss: 2.1056 - val_accuracy: 0.3968\n",
            "Epoch 196/10000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 2.0036 - accuracy: 0.3928 - val_loss: 2.1034 - val_accuracy: 0.4003\n",
            "Epoch 197/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.0235 - accuracy: 0.3932 - val_loss: 2.1036 - val_accuracy: 0.4046\n",
            "Epoch 198/10000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 2.0134 - accuracy: 0.3888 - val_loss: 2.1030 - val_accuracy: 0.4061\n",
            "Epoch 199/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.0033 - accuracy: 0.3950 - val_loss: 2.1018 - val_accuracy: 0.4077\n",
            "Epoch 200/10000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 2.0066 - accuracy: 0.3882 - val_loss: 2.0989 - val_accuracy: 0.4081\n",
            "Epoch 201/10000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 2.0001 - accuracy: 0.3929 - val_loss: 2.0954 - val_accuracy: 0.4050\n",
            "Epoch 202/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.0030 - accuracy: 0.3916 - val_loss: 2.0946 - val_accuracy: 0.4065\n",
            "Epoch 203/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.9974 - accuracy: 0.3958 - val_loss: 2.0961 - val_accuracy: 0.4050\n",
            "Epoch 204/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.9994 - accuracy: 0.3929 - val_loss: 2.0976 - val_accuracy: 0.4015\n",
            "Epoch 205/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 1.9884 - accuracy: 0.3982 - val_loss: 2.0956 - val_accuracy: 0.4077\n",
            "Epoch 206/10000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.9880 - accuracy: 0.3990 - val_loss: 2.0924 - val_accuracy: 0.4054\n",
            "Epoch 207/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 1.9835 - accuracy: 0.3971 - val_loss: 2.0895 - val_accuracy: 0.4089\n",
            "Epoch 208/10000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 1.9813 - accuracy: 0.4033 - val_loss: 2.0877 - val_accuracy: 0.4131\n",
            "Epoch 209/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.9750 - accuracy: 0.4056 - val_loss: 2.0884 - val_accuracy: 0.4139\n",
            "Epoch 210/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.9846 - accuracy: 0.3995 - val_loss: 2.0882 - val_accuracy: 0.4108\n",
            "Epoch 211/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.9687 - accuracy: 0.4049 - val_loss: 2.0860 - val_accuracy: 0.4077\n",
            "Epoch 212/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.9951 - accuracy: 0.3987 - val_loss: 2.0826 - val_accuracy: 0.4085\n",
            "Epoch 213/10000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 1.9760 - accuracy: 0.4007 - val_loss: 2.0815 - val_accuracy: 0.4081\n",
            "Epoch 214/10000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.9711 - accuracy: 0.4037 - val_loss: 2.0814 - val_accuracy: 0.4046\n",
            "Epoch 215/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 1.9788 - accuracy: 0.4015 - val_loss: 2.0791 - val_accuracy: 0.4058\n",
            "Epoch 216/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 1.9736 - accuracy: 0.3986 - val_loss: 2.0790 - val_accuracy: 0.4073\n",
            "Epoch 217/10000\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 1.9589 - accuracy: 0.4008 - val_loss: 2.0781 - val_accuracy: 0.4081\n",
            "Epoch 218/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 1.9554 - accuracy: 0.4113 - val_loss: 2.0771 - val_accuracy: 0.4042\n",
            "Epoch 219/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 1.9667 - accuracy: 0.4006 - val_loss: 2.0740 - val_accuracy: 0.4042\n",
            "Epoch 220/10000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.9634 - accuracy: 0.4053 - val_loss: 2.0698 - val_accuracy: 0.4127\n",
            "Epoch 221/10000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.9565 - accuracy: 0.4085 - val_loss: 2.0694 - val_accuracy: 0.4116\n",
            "Epoch 222/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.9576 - accuracy: 0.3972 - val_loss: 2.0702 - val_accuracy: 0.4127\n",
            "Epoch 223/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.9418 - accuracy: 0.4051 - val_loss: 2.0718 - val_accuracy: 0.4108\n",
            "Epoch 224/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.9475 - accuracy: 0.4020 - val_loss: 2.0712 - val_accuracy: 0.4073\n",
            "Epoch 225/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 1.9375 - accuracy: 0.4070 - val_loss: 2.0680 - val_accuracy: 0.4092\n",
            "Epoch 226/10000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 1.9379 - accuracy: 0.4093 - val_loss: 2.0674 - val_accuracy: 0.4112\n",
            "Epoch 227/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 1.9410 - accuracy: 0.4045 - val_loss: 2.0673 - val_accuracy: 0.4089\n",
            "Epoch 228/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.9458 - accuracy: 0.4069 - val_loss: 2.0674 - val_accuracy: 0.4073\n",
            "Epoch 229/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 1.9292 - accuracy: 0.4089 - val_loss: 2.0667 - val_accuracy: 0.4096\n",
            "Epoch 230/10000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 1.9278 - accuracy: 0.4104 - val_loss: 2.0638 - val_accuracy: 0.4096\n",
            "Epoch 231/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.9294 - accuracy: 0.4054 - val_loss: 2.0598 - val_accuracy: 0.4139\n",
            "Epoch 232/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 1.9249 - accuracy: 0.4096 - val_loss: 2.0580 - val_accuracy: 0.4162\n",
            "Epoch 233/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.9303 - accuracy: 0.4084 - val_loss: 2.0570 - val_accuracy: 0.4135\n",
            "Epoch 234/10000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.9340 - accuracy: 0.4096 - val_loss: 2.0565 - val_accuracy: 0.4120\n",
            "Epoch 235/10000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.9225 - accuracy: 0.4127 - val_loss: 2.0564 - val_accuracy: 0.4108\n",
            "Epoch 236/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.9140 - accuracy: 0.4125 - val_loss: 2.0545 - val_accuracy: 0.4147\n",
            "Epoch 237/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 1.9311 - accuracy: 0.4109 - val_loss: 2.0531 - val_accuracy: 0.4131\n",
            "Epoch 238/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.9082 - accuracy: 0.4170 - val_loss: 2.0539 - val_accuracy: 0.4100\n",
            "Epoch 239/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.9122 - accuracy: 0.4160 - val_loss: 2.0557 - val_accuracy: 0.4096\n",
            "Epoch 240/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.9237 - accuracy: 0.4080 - val_loss: 2.0562 - val_accuracy: 0.4089\n",
            "Epoch 241/10000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 1.9115 - accuracy: 0.4176 - val_loss: 2.0527 - val_accuracy: 0.4116\n",
            "Epoch 242/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 1.9058 - accuracy: 0.4202 - val_loss: 2.0486 - val_accuracy: 0.4143\n",
            "Epoch 243/10000\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 1.9068 - accuracy: 0.4189 - val_loss: 2.0456 - val_accuracy: 0.4151\n",
            "Epoch 244/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.9027 - accuracy: 0.4172 - val_loss: 2.0459 - val_accuracy: 0.4135\n",
            "Epoch 245/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.8940 - accuracy: 0.4164 - val_loss: 2.0465 - val_accuracy: 0.4116\n",
            "Epoch 246/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.9083 - accuracy: 0.4124 - val_loss: 2.0486 - val_accuracy: 0.4127\n",
            "Epoch 247/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.8928 - accuracy: 0.4165 - val_loss: 2.0483 - val_accuracy: 0.4108\n",
            "Epoch 248/10000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.8862 - accuracy: 0.4221 - val_loss: 2.0436 - val_accuracy: 0.4143\n",
            "Epoch 249/10000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.8860 - accuracy: 0.4242 - val_loss: 2.0432 - val_accuracy: 0.4135\n",
            "Epoch 250/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.8849 - accuracy: 0.4195 - val_loss: 2.0420 - val_accuracy: 0.4170\n",
            "Epoch 251/10000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 1.8840 - accuracy: 0.4145 - val_loss: 2.0407 - val_accuracy: 0.4131\n",
            "Epoch 252/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 1.8915 - accuracy: 0.4195 - val_loss: 2.0420 - val_accuracy: 0.4112\n",
            "Epoch 253/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.8819 - accuracy: 0.4237 - val_loss: 2.0413 - val_accuracy: 0.4135\n",
            "Epoch 254/10000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 1.8825 - accuracy: 0.4236 - val_loss: 2.0389 - val_accuracy: 0.4151\n",
            "Epoch 255/10000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.8801 - accuracy: 0.4248 - val_loss: 2.0348 - val_accuracy: 0.4186\n",
            "Epoch 256/10000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.8762 - accuracy: 0.4205 - val_loss: 2.0313 - val_accuracy: 0.4221\n",
            "Epoch 257/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.8572 - accuracy: 0.4299 - val_loss: 2.0325 - val_accuracy: 0.4178\n",
            "Epoch 258/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 1.8744 - accuracy: 0.4197 - val_loss: 2.0346 - val_accuracy: 0.4116\n",
            "Epoch 259/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.8468 - accuracy: 0.4288 - val_loss: 2.0349 - val_accuracy: 0.4120\n",
            "Epoch 260/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.8629 - accuracy: 0.4264 - val_loss: 2.0338 - val_accuracy: 0.4108\n",
            "Epoch 261/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.8814 - accuracy: 0.4219 - val_loss: 2.0314 - val_accuracy: 0.4143\n",
            "Epoch 262/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.8648 - accuracy: 0.4266 - val_loss: 2.0314 - val_accuracy: 0.4143\n",
            "Epoch 263/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.8551 - accuracy: 0.4285 - val_loss: 2.0331 - val_accuracy: 0.4131\n",
            "Epoch 264/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.8651 - accuracy: 0.4341 - val_loss: 2.0344 - val_accuracy: 0.4116\n",
            "Epoch 265/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.8438 - accuracy: 0.4349 - val_loss: 2.0336 - val_accuracy: 0.4124\n",
            "Epoch 266/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.8543 - accuracy: 0.4303 - val_loss: 2.0327 - val_accuracy: 0.4186\n",
            "Epoch 267/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.8554 - accuracy: 0.4275 - val_loss: 2.0316 - val_accuracy: 0.4151\n",
            "Epoch 268/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.8625 - accuracy: 0.4275 - val_loss: 2.0308 - val_accuracy: 0.4127\n",
            "Epoch 269/10000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 1.8536 - accuracy: 0.4286 - val_loss: 2.0303 - val_accuracy: 0.4073\n",
            "Epoch 270/10000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.8457 - accuracy: 0.4326 - val_loss: 2.0302 - val_accuracy: 0.4081\n",
            "Epoch 271/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 1.8406 - accuracy: 0.4333 - val_loss: 2.0292 - val_accuracy: 0.4092\n",
            "Epoch 272/10000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.8368 - accuracy: 0.4326 - val_loss: 2.0280 - val_accuracy: 0.4143\n",
            "Epoch 273/10000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.8421 - accuracy: 0.4269 - val_loss: 2.0260 - val_accuracy: 0.4151\n",
            "Epoch 274/10000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.8287 - accuracy: 0.4299 - val_loss: 2.0259 - val_accuracy: 0.4162\n",
            "Epoch 275/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.8324 - accuracy: 0.4335 - val_loss: 2.0272 - val_accuracy: 0.4135\n",
            "Epoch 276/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.8306 - accuracy: 0.4285 - val_loss: 2.0288 - val_accuracy: 0.4112\n",
            "Epoch 277/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.8180 - accuracy: 0.4384 - val_loss: 2.0300 - val_accuracy: 0.4135\n",
            "Epoch 278/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.8233 - accuracy: 0.4361 - val_loss: 2.0318 - val_accuracy: 0.4124\n",
            "Epoch 279/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 1.8288 - accuracy: 0.4324 - val_loss: 2.0304 - val_accuracy: 0.4139\n",
            "Epoch 280/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.8185 - accuracy: 0.4420 - val_loss: 2.0290 - val_accuracy: 0.4112\n",
            "Epoch 281/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.8098 - accuracy: 0.4377 - val_loss: 2.0286 - val_accuracy: 0.4143\n",
            "Epoch 282/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.8268 - accuracy: 0.4299 - val_loss: 2.0285 - val_accuracy: 0.4162\n",
            "Epoch 283/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.8181 - accuracy: 0.4348 - val_loss: 2.0310 - val_accuracy: 0.4077\n",
            "Epoch 284/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.8073 - accuracy: 0.4426 - val_loss: 2.0307 - val_accuracy: 0.4061\n",
            "Epoch 285/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.8180 - accuracy: 0.4345 - val_loss: 2.0283 - val_accuracy: 0.4089\n",
            "Epoch 286/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.8074 - accuracy: 0.4370 - val_loss: 2.0271 - val_accuracy: 0.4058\n",
            "Epoch 287/10000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.8134 - accuracy: 0.4403 - val_loss: 2.0251 - val_accuracy: 0.4085\n",
            "Epoch 288/10000\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 1.8137 - accuracy: 0.4439 - val_loss: 2.0246 - val_accuracy: 0.4077\n",
            "Epoch 289/10000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.7988 - accuracy: 0.4343 - val_loss: 2.0241 - val_accuracy: 0.4096\n",
            "Epoch 290/10000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.8002 - accuracy: 0.4365 - val_loss: 2.0223 - val_accuracy: 0.4143\n",
            "Epoch 291/10000\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 1.8027 - accuracy: 0.4428 - val_loss: 2.0207 - val_accuracy: 0.4170\n",
            "Epoch 292/10000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 1.8074 - accuracy: 0.4447 - val_loss: 2.0194 - val_accuracy: 0.4166\n",
            "Epoch 293/10000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.7938 - accuracy: 0.4433 - val_loss: 2.0190 - val_accuracy: 0.4162\n",
            "Epoch 294/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.7932 - accuracy: 0.4420 - val_loss: 2.0217 - val_accuracy: 0.4120\n",
            "Epoch 295/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.7822 - accuracy: 0.4434 - val_loss: 2.0241 - val_accuracy: 0.4108\n",
            "Epoch 296/10000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 1.7978 - accuracy: 0.4352 - val_loss: 2.0238 - val_accuracy: 0.4120\n",
            "Epoch 297/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.7884 - accuracy: 0.4438 - val_loss: 2.0247 - val_accuracy: 0.4116\n",
            "Epoch 298/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.7844 - accuracy: 0.4427 - val_loss: 2.0262 - val_accuracy: 0.4127\n",
            "Epoch 299/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.7720 - accuracy: 0.4460 - val_loss: 2.0247 - val_accuracy: 0.4147\n",
            "Epoch 300/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.7895 - accuracy: 0.4455 - val_loss: 2.0227 - val_accuracy: 0.4151\n",
            "Epoch 301/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.7733 - accuracy: 0.4483 - val_loss: 2.0204 - val_accuracy: 0.4151\n",
            "Epoch 302/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.7702 - accuracy: 0.4461 - val_loss: 2.0196 - val_accuracy: 0.4151\n",
            "Epoch 303/10000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 1.7857 - accuracy: 0.4421 - val_loss: 2.0199 - val_accuracy: 0.4112\n",
            "Epoch 304/10000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 1.7663 - accuracy: 0.4495 - val_loss: 2.0199 - val_accuracy: 0.4131\n",
            "Epoch 305/10000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 1.7862 - accuracy: 0.4370 - val_loss: 2.0152 - val_accuracy: 0.4159\n",
            "Epoch 306/10000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.7795 - accuracy: 0.4435 - val_loss: 2.0103 - val_accuracy: 0.4174\n",
            "Epoch 307/10000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.7610 - accuracy: 0.4519 - val_loss: 2.0092 - val_accuracy: 0.4162\n",
            "Epoch 308/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.7642 - accuracy: 0.4496 - val_loss: 2.0119 - val_accuracy: 0.4221\n",
            "Epoch 309/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.7715 - accuracy: 0.4474 - val_loss: 2.0166 - val_accuracy: 0.4124\n",
            "Epoch 310/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1.7703 - accuracy: 0.4477 - val_loss: 2.0146 - val_accuracy: 0.4131\n",
            "Epoch 311/10000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 1.7667 - accuracy: 0.4512 - val_loss: 2.0120 - val_accuracy: 0.4147\n",
            "Epoch 312/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.7674 - accuracy: 0.4502 - val_loss: 2.0119 - val_accuracy: 0.4162\n",
            "Epoch 313/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.7535 - accuracy: 0.4528 - val_loss: 2.0152 - val_accuracy: 0.4178\n",
            "Epoch 314/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.7519 - accuracy: 0.4478 - val_loss: 2.0174 - val_accuracy: 0.4170\n",
            "Epoch 315/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.7712 - accuracy: 0.4509 - val_loss: 2.0160 - val_accuracy: 0.4186\n",
            "Epoch 316/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.7560 - accuracy: 0.4486 - val_loss: 2.0154 - val_accuracy: 0.4166\n",
            "Epoch 317/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 1.7461 - accuracy: 0.4537 - val_loss: 2.0158 - val_accuracy: 0.4155\n",
            "Epoch 318/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.7602 - accuracy: 0.4538 - val_loss: 2.0163 - val_accuracy: 0.4186\n",
            "Epoch 319/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.7357 - accuracy: 0.4564 - val_loss: 2.0154 - val_accuracy: 0.4151\n",
            "Epoch 320/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.7438 - accuracy: 0.4526 - val_loss: 2.0139 - val_accuracy: 0.4131\n",
            "Epoch 321/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.7552 - accuracy: 0.4528 - val_loss: 2.0116 - val_accuracy: 0.4112\n",
            "Epoch 322/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 1.7438 - accuracy: 0.4487 - val_loss: 2.0113 - val_accuracy: 0.4085\n",
            "Epoch 323/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.7321 - accuracy: 0.4561 - val_loss: 2.0106 - val_accuracy: 0.4085\n",
            "Epoch 324/10000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 1.7330 - accuracy: 0.4555 - val_loss: 2.0107 - val_accuracy: 0.4058\n",
            "Epoch 325/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.7326 - accuracy: 0.4542 - val_loss: 2.0109 - val_accuracy: 0.4096\n",
            "Epoch 326/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.7248 - accuracy: 0.4617 - val_loss: 2.0116 - val_accuracy: 0.4112\n",
            "Epoch 327/10000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 1.7181 - accuracy: 0.4621 - val_loss: 2.0115 - val_accuracy: 0.4127\n",
            "Epoch 328/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.7386 - accuracy: 0.4545 - val_loss: 2.0108 - val_accuracy: 0.4131\n",
            "Epoch 329/10000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 1.7238 - accuracy: 0.4596 - val_loss: 2.0112 - val_accuracy: 0.4127\n",
            "Epoch 330/10000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 1.7185 - accuracy: 0.4600 - val_loss: 2.0109 - val_accuracy: 0.4116\n",
            "Epoch 331/10000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 1.7128 - accuracy: 0.4576 - val_loss: 2.0111 - val_accuracy: 0.4120\n",
            "Epoch 332/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.7201 - accuracy: 0.4589 - val_loss: 2.0127 - val_accuracy: 0.4124\n",
            "Epoch 333/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.7227 - accuracy: 0.4596 - val_loss: 2.0149 - val_accuracy: 0.4073\n",
            "Epoch 334/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.7122 - accuracy: 0.4618 - val_loss: 2.0145 - val_accuracy: 0.4127\n",
            "Epoch 335/10000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 1.7107 - accuracy: 0.4580 - val_loss: 2.0137 - val_accuracy: 0.4120\n",
            "Epoch 336/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.7171 - accuracy: 0.4557 - val_loss: 2.0115 - val_accuracy: 0.4151\n",
            "Epoch 337/10000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 1.7149 - accuracy: 0.4597 - val_loss: 2.0136 - val_accuracy: 0.4139\n",
            "Epoch 338/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.7059 - accuracy: 0.4607 - val_loss: 2.0160 - val_accuracy: 0.4100\n",
            "Epoch 339/10000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 1.6996 - accuracy: 0.4605 - val_loss: 2.0183 - val_accuracy: 0.4081\n",
            "Epoch 340/10000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 1.7081 - accuracy: 0.4612 - val_loss: 2.0145 - val_accuracy: 0.4124\n",
            "Epoch 341/10000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.7221 - accuracy: 0.4541 - val_loss: 2.0090 - val_accuracy: 0.4124\n",
            "Epoch 342/10000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.7032 - accuracy: 0.4603 - val_loss: 2.0043 - val_accuracy: 0.4127\n",
            "Epoch 343/10000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.7045 - accuracy: 0.4600 - val_loss: 2.0032 - val_accuracy: 0.4159\n",
            "Epoch 344/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.7045 - accuracy: 0.4635 - val_loss: 2.0034 - val_accuracy: 0.4139\n",
            "Epoch 345/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.7101 - accuracy: 0.4570 - val_loss: 2.0058 - val_accuracy: 0.4174\n",
            "Epoch 346/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.6943 - accuracy: 0.4670 - val_loss: 2.0064 - val_accuracy: 0.4178\n",
            "Epoch 347/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.7054 - accuracy: 0.4663 - val_loss: 2.0042 - val_accuracy: 0.4186\n",
            "Epoch 348/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.6940 - accuracy: 0.4665 - val_loss: 2.0067 - val_accuracy: 0.4194\n",
            "Epoch 349/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.6926 - accuracy: 0.4717 - val_loss: 2.0099 - val_accuracy: 0.4155\n",
            "Epoch 350/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 1.6785 - accuracy: 0.4777 - val_loss: 2.0138 - val_accuracy: 0.4174\n",
            "Epoch 351/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.6851 - accuracy: 0.4704 - val_loss: 2.0179 - val_accuracy: 0.4131\n",
            "Epoch 352/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.6949 - accuracy: 0.4693 - val_loss: 2.0200 - val_accuracy: 0.4178\n",
            "Epoch 353/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.6994 - accuracy: 0.4658 - val_loss: 2.0214 - val_accuracy: 0.4182\n",
            "Epoch 354/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.6846 - accuracy: 0.4675 - val_loss: 2.0222 - val_accuracy: 0.4155\n",
            "Epoch 355/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.6758 - accuracy: 0.4677 - val_loss: 2.0167 - val_accuracy: 0.4182\n",
            "Epoch 356/10000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 1.6808 - accuracy: 0.4671 - val_loss: 2.0123 - val_accuracy: 0.4174\n",
            "Epoch 357/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.6663 - accuracy: 0.4764 - val_loss: 2.0106 - val_accuracy: 0.4178\n",
            "Epoch 358/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.6724 - accuracy: 0.4738 - val_loss: 2.0091 - val_accuracy: 0.4217\n",
            "Epoch 359/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.6751 - accuracy: 0.4666 - val_loss: 2.0104 - val_accuracy: 0.4236\n",
            "Epoch 360/10000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 1.6832 - accuracy: 0.4663 - val_loss: 2.0107 - val_accuracy: 0.4174\n",
            "Epoch 361/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.6657 - accuracy: 0.4760 - val_loss: 2.0077 - val_accuracy: 0.4197\n",
            "Epoch 362/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.6694 - accuracy: 0.4735 - val_loss: 2.0063 - val_accuracy: 0.4190\n",
            "Epoch 363/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 1.6703 - accuracy: 0.4682 - val_loss: 2.0077 - val_accuracy: 0.4205\n",
            "Epoch 364/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.6857 - accuracy: 0.4619 - val_loss: 2.0092 - val_accuracy: 0.4229\n",
            "Epoch 365/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.6557 - accuracy: 0.4741 - val_loss: 2.0094 - val_accuracy: 0.4248\n",
            "Epoch 366/10000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 1.6564 - accuracy: 0.4807 - val_loss: 2.0080 - val_accuracy: 0.4236\n",
            "Epoch 367/10000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 1.6564 - accuracy: 0.4763 - val_loss: 2.0089 - val_accuracy: 0.4244\n",
            "Epoch 368/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.6735 - accuracy: 0.4673 - val_loss: 2.0126 - val_accuracy: 0.4240\n",
            "Epoch 369/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.6602 - accuracy: 0.4711 - val_loss: 2.0146 - val_accuracy: 0.4205\n",
            "Epoch 370/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.6572 - accuracy: 0.4729 - val_loss: 2.0171 - val_accuracy: 0.4190\n",
            "Epoch 371/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1.6519 - accuracy: 0.4719 - val_loss: 2.0157 - val_accuracy: 0.4194\n",
            "Epoch 372/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.6521 - accuracy: 0.4721 - val_loss: 2.0172 - val_accuracy: 0.4174\n",
            "Epoch 373/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.6619 - accuracy: 0.4719 - val_loss: 2.0183 - val_accuracy: 0.4170\n",
            "Epoch 374/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.6447 - accuracy: 0.4768 - val_loss: 2.0182 - val_accuracy: 0.4147\n",
            "Epoch 375/10000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 1.6465 - accuracy: 0.4746 - val_loss: 2.0165 - val_accuracy: 0.4147\n",
            "Epoch 376/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 1.6427 - accuracy: 0.4787 - val_loss: 2.0153 - val_accuracy: 0.4151\n",
            "Epoch 377/10000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 1.6535 - accuracy: 0.4764 - val_loss: 2.0156 - val_accuracy: 0.4143\n",
            "Epoch 378/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.6547 - accuracy: 0.4725 - val_loss: 2.0160 - val_accuracy: 0.4162\n",
            "Epoch 379/10000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.6290 - accuracy: 0.4786 - val_loss: 2.0149 - val_accuracy: 0.4174\n",
            "Epoch 380/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.6331 - accuracy: 0.4775 - val_loss: 2.0139 - val_accuracy: 0.4162\n",
            "Epoch 381/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.6366 - accuracy: 0.4775 - val_loss: 2.0168 - val_accuracy: 0.4159\n",
            "Epoch 382/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 1.6349 - accuracy: 0.4840 - val_loss: 2.0191 - val_accuracy: 0.4124\n",
            "Epoch 383/10000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 1.6394 - accuracy: 0.4816 - val_loss: 2.0238 - val_accuracy: 0.4174\n",
            "Epoch 384/10000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 1.6391 - accuracy: 0.4813 - val_loss: 2.0243 - val_accuracy: 0.4166\n",
            "Epoch 385/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.6473 - accuracy: 0.4797 - val_loss: 2.0220 - val_accuracy: 0.4151\n",
            "Epoch 386/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.6222 - accuracy: 0.4821 - val_loss: 2.0197 - val_accuracy: 0.4135\n",
            "Epoch 387/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.6246 - accuracy: 0.4814 - val_loss: 2.0195 - val_accuracy: 0.4201\n",
            "Epoch 388/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 1.6175 - accuracy: 0.4796 - val_loss: 2.0208 - val_accuracy: 0.4151\n",
            "Epoch 389/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.6195 - accuracy: 0.4845 - val_loss: 2.0212 - val_accuracy: 0.4124\n",
            "Epoch 390/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.6259 - accuracy: 0.4814 - val_loss: 2.0222 - val_accuracy: 0.4127\n",
            "Epoch 391/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.6129 - accuracy: 0.4842 - val_loss: 2.0146 - val_accuracy: 0.4135\n",
            "Epoch 392/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.6128 - accuracy: 0.4871 - val_loss: 2.0104 - val_accuracy: 0.4135\n",
            "Epoch 393/10000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 1.6256 - accuracy: 0.4821 - val_loss: 2.0104 - val_accuracy: 0.4151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYSMrE1kS0gS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e1d245-112c-4e6f-fab4-896d76535896"
      },
      "source": [
        "Y_pred = model_full.predict(x_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4062149007862224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTY6cT5cvXmY",
        "outputId": "a05d65da-24f4-4210-bf80-592d5600eb06"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.54      0.63      0.58       125\n",
            "         1.0       0.17      0.13      0.15        61\n",
            "         2.0       0.36      0.49      0.42       132\n",
            "         3.0       0.20      0.20      0.20        81\n",
            "         4.0       0.47      0.48      0.47       213\n",
            "         5.0       0.21      0.44      0.28       100\n",
            "         6.0       0.44      0.71      0.55        89\n",
            "         7.0       0.86      0.87      0.86       123\n",
            "         8.0       0.24      0.27      0.25        85\n",
            "         9.0       0.50      0.68      0.57        77\n",
            "        10.0       0.40      0.52      0.45        71\n",
            "        11.0       0.37      0.23      0.28       115\n",
            "        12.0       0.41      0.39      0.40       114\n",
            "        13.0       0.27      0.11      0.16        79\n",
            "        14.0       0.69      0.45      0.55       191\n",
            "        15.0       0.18      0.22      0.19       116\n",
            "        16.0       0.23      0.21      0.22        99\n",
            "        17.0       0.56      0.39      0.46       218\n",
            "        18.0       0.25      0.30      0.27       123\n",
            "        19.0       0.44      0.27      0.33       270\n",
            "        20.0       0.52      0.61      0.56       119\n",
            "        21.0       0.16      0.11      0.13        70\n",
            "\n",
            "    accuracy                           0.41      2671\n",
            "   macro avg       0.38      0.40      0.38      2671\n",
            "weighted avg       0.42      0.41      0.40      2671\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAHyW7kVTYoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaba46a7-9abc-478f-a04f-69b0efb22c5d"
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 79   1   3   1   3   2   1   1   0   0   0   2   6   0   0   7   1   3\n",
            "    0   9   4   2]\n",
            " [  2   8   4   0   2   8   1   2   7   1   1   1   4   0   2   4   4   0\n",
            "    3   1   3   3]\n",
            " [  0   0  65   4   7  11  10   2   1   2   8   0   2   0   0   5   0   6\n",
            "    3   5   1   0]\n",
            " [  1   0   6  16  12   7   5   0   0   2   1   0   1   0   3   5   3   5\n",
            "    7   6   0   1]\n",
            " [  1   3  23   9 102   5  18   1   3   1   7   0   2   2   5   4   2   3\n",
            "    9   8   1   4]\n",
            " [  0   3   6   0   1  44   2   0   4   2   0   3   1   0   1   6   3  14\n",
            "    3   3   1   3]\n",
            " [  0   0   7   1   3   3  63   0   0   4   0   0   0   0   1   0   2   2\n",
            "    3   0   0   0]\n",
            " [  3   0   0   0   1   1   1 107   1   0   3   0   3   0   0   0   0   1\n",
            "    0   0   2   0]\n",
            " [  9   2   0   2   3   4   0   0  23   2   1   5   1   1   0   3   5   1\n",
            "    4  11   6   2]\n",
            " [  1   0   1   0   5   1   3   0   3  52   2   0   1   0   4   0   0   0\n",
            "    0   0   4   0]\n",
            " [  5   0   7   2   2   1   2   2   1   2  37   0   0   0   0   1   2   2\n",
            "    3   2   0   0]\n",
            " [  6   5   6   3   1  10   4   0   7   2   3  26   2   0   2   9   4   5\n",
            "    5   7   2   6]\n",
            " [  7   1   0   1   2   9   0   2   0   2   0   0  45   2   4   8   4   0\n",
            "    6   6  12   3]\n",
            " [  4   2   2   1   5   6   5   0   3   0   1   1   8   9   5   2   2   0\n",
            "   18   4   1   0]\n",
            " [  8   3   4   4  18   6   3   1   0  19   2   2   9   3  86   5   2   2\n",
            "    4   2   5   3]\n",
            " [  7   3   1   3   7  19   0   0   2   1   1   3   6   3   2  25   4   4\n",
            "   10  12   1   2]\n",
            " [  1   4   9   4   8   7   0   0   6   1   2   3   2   1   1   5  21   4\n",
            "   12   3   4   1]\n",
            " [  0   0  15   6   4  38   8   0   9   0   3  14   0   2   0  13   4  86\n",
            "    6   7   1   2]\n",
            " [  0   1   6   7  13   7   5   1   6   0   8   0   0   4   1   8   9   1\n",
            "   37   3   2   4]\n",
            " [ 10   8  15  14  14  13   7   2   9   3  10   4  11   5   3  19  10  10\n",
            "   10  73  15   5]\n",
            " [  1   3   0   0   0   1   2   1   7   8   0   4   4   0   2   5   3   2\n",
            "    0   3  73   0]\n",
            " [  2   1   0   1   5   7   2   3   5   1   3   3   1   1   2   7   8   2\n",
            "    4   2   2   8]]\n"
          ]
        }
      ]
    }
  ]
}